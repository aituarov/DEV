{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1                       2\n",
      "0  1  2  {'a': 'ab', 'b': 'bb'}\n",
      "1  3  4  {'c': 'cb', 'd': 'dd'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "first = [1, 2, {\"a\": \"ab\", \"b\": \"bb\"}]\n",
    "second = [3, 4, {\"c\": \"cb\", \"d\": \"dd\"}]\n",
    "a = pd.DataFrame([first, second] )\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lxml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d89421e09647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlxml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lxml'"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "__author__ = 'aituarov'\n",
    "\n",
    "\n",
    "DB_LOADER_DIR = 'C:\\\\DEV\\\\Dias\\\\'\n",
    "\n",
    "\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'}\n",
    "\n",
    "category_urls = ['https://shop.akpo.by/vytyazhki',\n",
    "                'https://shop.akpo.by/varochnye-paneli',\n",
    "                 'https://shop.akpo.by/duhovye-shkafy',\n",
    "                 'https://shop.akpo.by/posudomoechnye-mashiny',\n",
    "                 'https://shop.akpo.by/mikrovolnovye-pechi',\n",
    "                 'https://shop.akpo.by/aksessuary'\n",
    "                ]\n",
    "\n",
    "def get_product_urls():\n",
    "    main_url_products = set()\n",
    "    \n",
    "    for main_url in category_urls:\n",
    "        main_response = requests.get(main_url, headers=header)\n",
    "        main_page = html.fromstring(main_response.text)\n",
    "\n",
    "        page_urls = {main_url}\n",
    "        product_page_urls_el = main_page.xpath('//ul[@class=\"pagination\"]/li/a')\n",
    "        [page_urls.add(page_el.get('href')) for page_el in product_page_urls_el]\n",
    "\n",
    "\n",
    "        for url in page_urls:\n",
    "            print(\"Getting product urls from \" + url)\n",
    "            response = requests.get(url, headers=header)\n",
    "            page = html.fromstring(response.text)\n",
    "            product_div_els = page.xpath('//div[@id=\"content\"]/div[@class=\"row\"]')[0]\n",
    "            products = product_div_els.xpath('//div[@class=\"product-thumb\"]//div[@class=\"caption\"]/h4/a')\n",
    "            for product in products:\n",
    "                main_url_products.add(product.get('href'))\n",
    "\n",
    "        page_urls.clear()\n",
    "            \n",
    "    return main_url_products\n",
    "\n",
    "\n",
    "\n",
    "def get_products_info(urls_set):\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for url in urls_set:\n",
    "        category = url.split('/')[-2]\n",
    "\n",
    "        response = requests.get(url, headers=header)\n",
    "        page = html.fromstring(response.text)\n",
    "\n",
    "        name = page.xpath('//h1[@class=\"pr-name\"]')[0].text\n",
    "\n",
    "        price = page.xpath('//span[@class=\"autocalc-product-price\"]')[0].text\n",
    "\n",
    "        images_urls = []\n",
    "        images_el = page.xpath('//div[@id=\"fix_image\"]//a')\n",
    "        for image_el in images_el:\n",
    "            images_urls.append(image_el.get('href'))\n",
    "\n",
    "        characters = {}\n",
    "        char_rows = page.xpath('//div[@class=\"tab-content\"]//tbody/tr')\n",
    "        for row in char_rows:\n",
    "            char_name = row.xpath('.//td')[0].text\n",
    "            char_value = row.xpath('.//td')[1].text\n",
    "            characters[char_name] = char_value\n",
    "\n",
    "        data = data.append([[category, url, name, price, images_urls, characters]], ignore_index=True)\n",
    "        print(\"Got data from \" + url)\n",
    "        \n",
    "    data.columns = ['category','url', 'name', 'price', 'images','characters']\n",
    "    print(data)\n",
    "#     data.to_excel(DB_LOADER_DIR + 'new_products.xlsx', sheet_name = 'AKPO')\n",
    "#     print(\"End.\")\n",
    "#     print(data)\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    product_urls = get_product_urls()\n",
    "    print(\"\\nProduct urls collected\")\n",
    "    \n",
    "    get_products_info(product_urls)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got data from https://ecostone73.ru/moiki/es-10/\n",
      "Got data from https://ecostone73.ru/moiki/es-10/\n",
      "Got data from https://ecostone73.ru/moiki/es-10/\n",
      "Got data from https://ecostone73.ru/moiki/es-11/\n",
      "Got data from https://ecostone73.ru/moiki/es-11/\n",
      "Got data from https://ecostone73.ru/moiki/es-11/\n",
      "Got data from https://ecostone73.ru/moiki/es-12/\n",
      "Got data from https://ecostone73.ru/moiki/es-12/\n",
      "Got data from https://ecostone73.ru/moiki/es-12/\n",
      "Got data from https://ecostone73.ru/moiki/es-13/\n",
      "Got data from https://ecostone73.ru/moiki/es-13/\n",
      "Got data from https://ecostone73.ru/moiki/es-13/\n",
      "Got data from https://ecostone73.ru/moiki/es-14/\n",
      "Got data from https://ecostone73.ru/moiki/es-14/\n",
      "Got data from https://ecostone73.ru/moiki/es-14/\n",
      "Got data from https://ecostone73.ru/moiki/es-15/\n",
      "Got data from https://ecostone73.ru/moiki/es-15/\n",
      "Got data from https://ecostone73.ru/moiki/es-15/\n",
      "Got data from https://ecostone73.ru/moiki/es-16/\n",
      "Got data from https://ecostone73.ru/moiki/es-16/\n",
      "Got data from https://ecostone73.ru/moiki/es-16/\n",
      "Got data from https://ecostone73.ru/moiki/es-17/\n",
      "Got data from https://ecostone73.ru/moiki/es-17/\n",
      "Got data from https://ecostone73.ru/moiki/es-17/\n",
      "Got data from https://ecostone73.ru/moiki/es-18/\n",
      "Got data from https://ecostone73.ru/moiki/es-18/\n",
      "Got data from https://ecostone73.ru/moiki/es-18/\n",
      "Got data from https://ecostone73.ru/moiki/es-19/\n",
      "Got data from https://ecostone73.ru/moiki/es-19/\n",
      "Got data from https://ecostone73.ru/moiki/es-19/\n",
      "Got data from https://ecostone73.ru/moiki/es-20/\n",
      "Got data from https://ecostone73.ru/moiki/es-20/\n",
      "Got data from https://ecostone73.ru/moiki/es-20/\n",
      "Got data from https://ecostone73.ru/moiki/es-21/\n",
      "Got data from https://ecostone73.ru/moiki/es-21/\n",
      "Got data from https://ecostone73.ru/moiki/es-21/\n",
      "Got data from https://ecostone73.ru/moiki/es-22/\n",
      "Got data from https://ecostone73.ru/moiki/es-22/\n",
      "Got data from https://ecostone73.ru/moiki/es-22/\n",
      "Got data from https://ecostone73.ru/moiki/es-23/\n",
      "Got data from https://ecostone73.ru/moiki/es-23/\n",
      "Got data from https://ecostone73.ru/moiki/es-23/\n",
      "Got data from https://ecostone73.ru/moiki/es-24/\n",
      "Got data from https://ecostone73.ru/moiki/es-24/\n",
      "Got data from https://ecostone73.ru/moiki/es-24/\n",
      "Got data from https://ecostone73.ru/moiki/es-25/\n",
      "Got data from https://ecostone73.ru/moiki/es-25/\n",
      "Got data from https://ecostone73.ru/moiki/es-25/\n",
      "Got data from https://ecostone73.ru/moiki/es-26/\n",
      "Got data from https://ecostone73.ru/moiki/es-26/\n",
      "Got data from https://ecostone73.ru/moiki/es-26/\n",
      "Got data from https://ecostone73.ru/moiki/es-27/\n",
      "Got data from https://ecostone73.ru/moiki/es-27/\n",
      "Got data from https://ecostone73.ru/moiki/es-27/\n",
      "Got data from https://ecostone73.ru/moiki/es-28/\n",
      "Got data from https://ecostone73.ru/moiki/es-28/\n",
      "Got data from https://ecostone73.ru/moiki/es-28/\n",
      "Got data from https://ecostone73.ru/moiki/es-29/\n",
      "Got data from https://ecostone73.ru/moiki/es-29/\n",
      "Got data from https://ecostone73.ru/moiki/es-29/\n",
      "Got data from https://ecostone73.ru/moiki/es-30/\n",
      "Got data from https://ecostone73.ru/moiki/es-30/\n",
      "Got data from https://ecostone73.ru/moiki/es-30/\n",
      "Got data from https://ecostone73.ru/moiki/es-31/\n",
      "Got data from https://ecostone73.ru/moiki/es-31/\n",
      "Got data from https://ecostone73.ru/moiki/es-31/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-01/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-01/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-01/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-01/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-02/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-02/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-02/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-03/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-03/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-03/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-03/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-04/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-04/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-04/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-04/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-05/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-05/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-05/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-05/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-06/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-06/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-06/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-07/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-07/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-07/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-07/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-08/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-08/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-08/\n",
      "Got data from https://ecostone73.ru/smesiteli/es-08/\n",
      "Got data from https://ecostone73.ru/dozators/es-1/\n",
      "Got data from https://ecostone73.ru/dozators/es-1/\n",
      "Got data from https://ecostone73.ru/dozators/es-1/\n",
      "Got data from https://ecostone73.ru/dozators/es-1/\n",
      "Got data from https://ecostone73.ru/dozators/es-2/\n",
      "Got data from https://ecostone73.ru/dozators/es-2/\n",
      "Got data from https://ecostone73.ru/dozators/es-2/\n",
      "Got data from https://ecostone73.ru/dozators/es-2/\n",
      "\n",
      "Product urls collected\n",
      "Got data from https://ecostone73.ru/es-20/\n",
      "Got data from https://ecostone73.ru/es-25/\n",
      "Got data from https://ecostone73.ru/es-06/\n",
      "Got data from https://ecostone73.ru/es-28/\n",
      "Got data from https://ecostone73.ru/es-29/\n",
      "Got data from https://ecostone73.ru/es-16/\n",
      "Got data from https://ecostone73.ru/es-21/\n",
      "Got data from https://ecostone73.ru/es-27/\n",
      "Got data from https://ecostone73.ru/es-30/\n",
      "Got data from https://ecostone73.ru/es-18/\n",
      "Got data from https://ecostone73.ru/es-31/\n",
      "Got data from https://ecostone73.ru/es-19/\n",
      "Got data from https://ecostone73.ru/es-13/\n",
      "Got data from https://ecostone73.ru/es-01/\n",
      "Got data from https://ecostone73.ru/es-04/\n",
      "Got data from https://ecostone73.ru/es-1/\n",
      "Got data from https://ecostone73.ru/es-12/\n",
      "Got data from https://ecostone73.ru/es-2/\n",
      "Got data from https://ecostone73.ru/es-26/\n",
      "Got data from https://ecostone73.ru/es-05/\n",
      "Got data from https://ecostone73.ru/es-07/\n",
      "Got data from https://ecostone73.ru/es-23/\n",
      "Got data from https://ecostone73.ru/es-02/\n",
      "Got data from https://ecostone73.ru/es-08/\n",
      "Got data from https://ecostone73.ru/es-17/\n",
      "Got data from https://ecostone73.ru/es-24/\n",
      "Got data from https://ecostone73.ru/es-22/\n",
      "Got data from https://ecostone73.ru/es-03/\n",
      "Got data from https://ecostone73.ru/es-10/\n",
      "Got data from https://ecostone73.ru/es-11/\n",
      "Got data from https://ecostone73.ru/es-14/\n",
      "Got data from https://ecostone73.ru/es-15/\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "__author__ = 'aituarov'\n",
    "\n",
    "\n",
    "DB_LOADER_DIR = 'C:\\\\DEV\\\\Dias\\\\'\n",
    "\n",
    "category_urls = ['https://ecostone73.ru/moiki',\n",
    "                 'https://ecostone73.ru/smesiteli',\n",
    "                 'https://ecostone73.ru/dozators'\n",
    "                ]\n",
    "\n",
    "\n",
    "def get_product_urls():\n",
    "    main_url_products = set()\n",
    "    \n",
    "    for main_url in category_urls:\n",
    "        main_response = requests.get(main_url)\n",
    "        main_page = html.fromstring(main_response.text)\n",
    "        \n",
    "        products_urls = main_page.xpath('//section[@id=\"section-content\"]//a')\n",
    "        for a in products_urls:\n",
    "            main_url_products.add(main_url + a.get('href'))\n",
    "            print('Got data from ' + main_url + a.get('href'))\n",
    "\n",
    "    return main_url_products\n",
    "\n",
    "\n",
    "def get_products_info(urls_set):\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for url in urls_set:\n",
    "        category = url.split('/')[-3]\n",
    "\n",
    "        url = url.replace('/' + category, '')\n",
    "        response = requests.get(url)\n",
    "        page = html.fromstring(response.text)\n",
    "\n",
    "        name=''\n",
    "        name_el = page.xpath('//p[@class=\"moto-text_system_5\"]/span')\n",
    "        for span in name_el:\n",
    "            if span.text!= None:\n",
    "                name+= span.text\n",
    "\n",
    "        try:\n",
    "            description = page.xpath('//p[@class=\"moto-text_218\"]/strong')[0].text\n",
    "        except IndexError:\n",
    "            description = ''\n",
    "\n",
    "        guarantee = page.xpath('//p[@class=\"moto-text_461\"]//text()')[1]\n",
    "\n",
    "        characters = {'Гарантия:': guarantee}\n",
    "        characters_el = page.xpath('//p[@class=\"moto-text_461\"]//text()')\n",
    "        for ind in range(len(characters_el)):\n",
    "            if characters_el[ind].endswith(':'):\n",
    "                characters[characters_el[ind]] = characters_el[ind+1]\n",
    "            elif characters_el[ind].startswith('•'):\n",
    "                characters[len(characters)] = characters_el[ind]\n",
    "\n",
    "        images_urls = []\n",
    "        image_front = page.xpath('//section[@id=\"section-content\"]//span[@class=\"moto-widget-image-link\"]/img')[0].get('data-src')\n",
    "        images_urls.append(url + image_front)\n",
    "        image_scheme = page.xpath('//p[contains(.,\"Схема:\")]/../../../..//img')[0].get('src')\n",
    "        images_urls.append(url + image_scheme)\n",
    "    \n",
    "        data = data.append([[category, url, name, None, images_urls, description, characters]], ignore_index=True)\n",
    "        print(\"Got data from \" + url)\n",
    "        \n",
    "    data.columns = ['category','url', 'name', 'price', 'images', 'description','characters']\n",
    "    data.to_excel(DB_LOADER_DIR + 'products_2.xlsx', sheet_name = 'ECOSTONE')\n",
    "    print(\"End.\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    product_urls = get_product_urls()\n",
    "    print(\"\\nProduct urls collected\")\n",
    "    \n",
    "    get_products_info(product_urls)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES-08\n",
      "/mt-content/uploads/2019/08/342.png\n",
      "/mt-content/uploads/2019/08/307.png\n",
      "/mt-content/uploads/2019/08/302.png\n",
      "/mt-content/uploads/2019/08/308.png\n",
      "/mt-content/uploads/2019/08/309.png\n",
      "/mt-content/uploads/2019/08/310.png\n",
      "/mt-content/uploads/2019/08/311.png\n",
      "/mt-content/uploads/2019/08/328.png\n",
      "/mt-content/uploads/2019/08/331.png\n",
      "/mt-content/uploads/2019/08/341.png\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "__author__ = 'aituarov'\n",
    "\n",
    "\n",
    "# DB_LOADER_DIR = 'C:\\\\DEV\\\\Dias\\\\'\n",
    "\n",
    "main_url = 'https://ecostone73.ru/'\n",
    "\n",
    "prod = [\n",
    "# 'ES-01',\n",
    "# 'ES-02',\n",
    "# 'ES-03',\n",
    "# 'ES-04',\n",
    "# 'ES-05',\n",
    "# 'ES-06',\n",
    "# 'ES-07',\n",
    "'ES-08',\n",
    "# 'ES-1',\n",
    "# 'ES-10',\n",
    "# 'ES-11',\n",
    "# 'ES-12',\n",
    "# 'ES-13',\n",
    "# 'ES-14',\n",
    "# 'ES-15',\n",
    "# 'ES-16',\n",
    "# 'ES-17',\n",
    "# 'ES-18',\n",
    "# 'ES-19',\n",
    "# 'ES-2',\n",
    "# 'ES-20',\n",
    "# 'ES-21',\n",
    "# 'ES-22',\n",
    "# 'ES-23',\n",
    "# 'ES-24',\n",
    "# 'ES-25',\n",
    "# 'ES-26',\n",
    "# 'ES-27',\n",
    "# 'ES-28',\n",
    "# 'ES-29',\n",
    "# 'ES-30',\n",
    "# 'ES-31'\n",
    "]\n",
    "\n",
    "\n",
    "def get_photos():\n",
    "    pict = {}\n",
    "    \n",
    "    for url in prod:\n",
    "        print(url)\n",
    "        prod_pict = []\n",
    "        response = requests.get(main_url + url)\n",
    "        page = html.fromstring(response.text)\n",
    "        \n",
    "        pictures = page.xpath('//p[contains(.,\"Посмотреть\")]/../../../..//a')\n",
    "#         pict[url] = pictures\n",
    "        \n",
    "    \n",
    "        \n",
    "        for el in pictures:\n",
    "# #             print(el.get('href'))\n",
    "            if el.get('href').split('/')[-3] == '2019':\n",
    "                prod_pict.append(main_url + el.get('href')[1:])\n",
    "                print(el.get('href'))\n",
    "            \n",
    "        pict[url] = prod_pict\n",
    "#         print(\"Len: \" + str(len(prod_pict)))\n",
    "    data = pd.DataFrame.from_dict(pict)\n",
    "#     print(data)\n",
    "    data.to_excel(r'C:\\\\DEV\\\\GV_S\\\\new_ecostone2.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "def get_product_urls():\n",
    "    main_url_products = set()\n",
    "    \n",
    "    for main_url in category_urls:\n",
    "        main_response = requests.get(main_url)\n",
    "        main_page = html.fromstring(main_response.text)\n",
    "        \n",
    "        products_urls = main_page.xpath('//section[@id=\"section-content\"]//a')\n",
    "        for a in products_urls:\n",
    "            main_url_products.add(main_url + a.get('href'))\n",
    "            print('Got data from ' + main_url + a.get('href'))\n",
    "\n",
    "    return main_url_products\n",
    "\n",
    "\n",
    "def get_products_info(urls_set):\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for url in urls_set:\n",
    "        category = url.split('/')[-3]\n",
    "\n",
    "        url = url.replace('/' + category, '')\n",
    "        response = requests.get(url)\n",
    "        page = html.fromstring(response.text)\n",
    "\n",
    "        name=''\n",
    "        name_el = page.xpath('//p[@class=\"moto-text_system_5\"]/span')\n",
    "        for span in name_el:\n",
    "            if span.text!= None:\n",
    "                name+= span.text\n",
    "\n",
    "        try:\n",
    "            description = page.xpath('//p[@class=\"moto-text_218\"]/strong')[0].text\n",
    "        except IndexError:\n",
    "            description = ''\n",
    "\n",
    "        guarantee = page.xpath('//p[@class=\"moto-text_461\"]//text()')[1]\n",
    "\n",
    "        characters = {'Гарантия:': guarantee}\n",
    "        characters_el = page.xpath('//p[@class=\"moto-text_461\"]//text()')\n",
    "        for ind in range(len(characters_el)):\n",
    "            if characters_el[ind].endswith(':'):\n",
    "                characters[characters_el[ind]] = characters_el[ind+1]\n",
    "            elif characters_el[ind].startswith('•'):\n",
    "                characters[len(characters)] = characters_el[ind]\n",
    "\n",
    "        images_urls = []\n",
    "        image_front = page.xpath('//section[@id=\"section-content\"]//span[@class=\"moto-widget-image-link\"]/img')[0].get('data-src')\n",
    "        images_urls.append(url + image_front)\n",
    "        image_scheme = page.xpath('//p[contains(.,\"Схема:\")]/../../../..//img')[0].get('src')\n",
    "        images_urls.append(url + image_scheme)\n",
    "    \n",
    "        data = data.append([[category, url, name, None, images_urls, description, characters]], ignore_index=True)\n",
    "        print(\"Got data from \" + url)\n",
    "        \n",
    "    data.columns = ['category','url', 'name', 'price', 'images', 'description','characters']\n",
    "    data.to_excel(DB_LOADER_DIR + 'products_2.xlsx', sheet_name = 'ECOSTONE')\n",
    "    print(\"End.\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "#     product_urls = get_product_urls()\n",
    "#     print(\"\\nProduct urls collected\")\n",
    "    \n",
    "#     get_products_info(product_urls)\n",
    "\n",
    "    get_photos()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
